{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/9vfy1vi6wsfkxyk/creditcard.csv.zip\n",
    "# !unzip creditcard.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Количество пропусков: {sum(data.isna().sum())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme()\n",
    "data[\"Class\"].hist()\n",
    "plt.xticks([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 56962)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[list(data.drop(columns=\"Class\"))]\n",
    "y = data[\"Class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: 4.396551345124884e-06\n",
      "w1: 0.0025380710659898475\n"
     ]
    }
   ],
   "source": [
    "weights_for_0 = 1.0 / len(y_train[y_train == 0])\n",
    "weights_for_1 = 1.0 / len(y_train[y_train == 1])\n",
    "print(f\"w0: {weights_for_0}\\nw1: {weights_for_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 56962)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X=X_train)\n",
    "X_test = scaler.transform(X=X_test)\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = X_train.shape[-1]\n",
    "hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.linear_1 = nn.Linear(in_features=in_shape, out_features=256)\n",
    "        self.linear_2 = nn.Linear(in_features=hidden_size, out_features=hidden_size*2)\n",
    "        self.linear_3 = nn.Linear(in_features=hidden_size*2, out_features=hidden_size)\n",
    "        self.linear_4 = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "\n",
    "        self.activation_1 = nn.ReLU() \n",
    "        self.activation_2 = nn.Sigmoid()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.activation_1(x)\n",
    "\n",
    "        x = self.linear_2(x)\n",
    "        x = self.activation_1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear_3(x)\n",
    "        x = self.activation_1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.linear_4(x)\n",
    "        x = self.activation_2(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "model = NN()\n",
    "weight = torch.tensor([weights_for_0, weights_for_1], dtype=torch.float)\n",
    "loss_fn = nn.BCELoss(weight=weight)\n",
    "optimizer = torch.optim.Adam(lr=0.01, params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n",
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.from_numpy((x)).to(torch.float32)\n",
    "        self.y = torch.Tensor(y.to_list()).unsqueeze(1).to(torch.float32)\n",
    "        \n",
    "        print(self.x.dtype, self.y.dtype)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "test_dataset = MyDataset(X_test, y_test)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=256)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: tensor([ -1.1221,  -8.4395,   5.1825, -12.3132,   6.7147,  -9.9410,  -2.1183,\n",
      "        -13.4322,   6.3246,  -7.7518, -12.9838,   5.1890, -10.8140,   1.6787,\n",
      "         -9.7700,   0.3947, -11.2833, -22.5889, -10.0214,   3.8089,  -1.9577,\n",
      "          1.6250,  -1.5531,  -3.7614,   1.1127,  -2.7076,  -0.9588,  -5.0235,\n",
      "         -3.1629,   1.0815])\n",
      "target: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print(f\"data: {test_dataset[0][0]}\")\n",
    "print(f\"target: {test_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data, target):\n",
    "    lst = []\n",
    "    for i in range(len(data)):\n",
    "        lst.append(data[i] == target[i])\n",
    "    return sum(lst) / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1]:   0%|          | 0/891 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [256, 1] doesn't match the broadcast shape [256, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[387], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m predict \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m---> 12\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Develop/Netology/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Develop/Netology/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Develop/Netology/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:621\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Develop/Netology/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3172\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3169\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3170\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [256, 1] doesn't match the broadcast shape [256, 2]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "predict_lst = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_progress_bar = tqdm(train_dataset, desc=f\"Epoch: [{i+1}/{EPOCHS}]\")\n",
    "    for idx, (data, target) in enumerate(train_progress_bar):\n",
    "        optimizer.zero_grad()\n",
    "        predict = model(data)\n",
    "        loss = loss_fn(predict, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 32 == 0:\n",
    "            train_progress_bar.set_description(f\"Epoch: [{i+1}/{EPOCHS}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    model.eval()\n",
    "    test_progress_bar = tqdm(test_dataset, desc=f\"Epoch: [{i+1}/{EPOCHS}]\")\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(test_progress_bar):\n",
    "            predict = model(data)\n",
    "            predict = torch.argmax(predict, dim=0)\n",
    "            predicts.append(predict.item())\n",
    "            targets.append(target.item())\n",
    "\n",
    "            if idx % 32 == 0:\n",
    "                test_progress_bar.set_description(f\"Epoch: [{i+1}/{EPOCHS}] Accuracy: {accuracy(data=predicts, target=targets)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
